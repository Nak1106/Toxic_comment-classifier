# ToxiFlow: Toxic Comment Classification

A research-grade implementation of multi-label toxic comment classification using the Jigsaw dataset.

## Project Structure

```
toxiflow/
â”œâ”€â”€ data/                           # Place jigsaw_train.csv here
â”œâ”€â”€ models/                         # Saved model checkpoints
â”œâ”€â”€ reports/                        # Metrics and results
â”œâ”€â”€ notebooks/                      # Research notebooks
â”‚   â”œâ”€â”€ 00_eda_preprocessing.ipynb           âœ… COMPLETE
â”‚   â”œâ”€â”€ 01_baseline_logreg_bilstm.ipynb      âœ… COMPLETE
â”‚   â”œâ”€â”€ 02_transformers_bert_distilbert_lexicon.ipynb  (TODO)
â”‚   â”œâ”€â”€ 03_contrastive_learning.ipynb        (TODO)
â”‚   â”œâ”€â”€ 04_calibration_thresholds.ipynb      (TODO)
â”‚   â”œâ”€â”€ 05_fairness_bias_analysis.ipynb      (TODO)
â”‚   â”œâ”€â”€ 06_ensembles_ablation.ipynb          (TODO)
â”‚   â””â”€â”€ 07_qualitative_cases.ipynb           (TODO)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                   # Configuration and hyperparameters
â”‚   â”œâ”€â”€ data_utils.py               # Data loading and preprocessing
â”‚   â”œâ”€â”€ metrics.py                  # Evaluation metrics
â”‚   â”œâ”€â”€ lexicon_utils.py            # Lexicon-based features
â”‚   â”œâ”€â”€ contrastive_dataset.py      # Contrastive learning dataset
â”‚   â”œâ”€â”€ calibration.py              # âœ¨ Temperature scaling, ECE
â”‚   â”œâ”€â”€ thresholds.py               # âœ¨ Threshold optimization
â”‚   â”œâ”€â”€ fairness_eval.py            # âœ¨ Bias evaluation
â”‚   â”œâ”€â”€ ensemble_eval.py            # âœ¨ Ensemble methods
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ rnn_models.py           # BiLSTM
â”‚   â”‚   â”œâ”€â”€ transformer_models.py   # BERT, DistilBERT, LexiconHybrid
â”‚   â”‚   â””â”€â”€ contrastive_model.py    # Contrastive encoder
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ bilstm_utils.py         # âœ¨ Reusable BiLSTM training
â”‚       â”œâ”€â”€ transformer_utils.py    # âœ¨ Reusable transformer training
â”‚       â”œâ”€â”€ lexicon_hybrid_utils.py # âœ¨ Lexicon hybrid training
â”‚       â”œâ”€â”€ contrastive_utils.py    # âœ¨ Contrastive learning training
â”‚       â”œâ”€â”€ train_bilstm.py         # CLI wrapper
â”‚       â”œâ”€â”€ train_transformer.py    # CLI wrapper
â”‚       â”œâ”€â”€ train_lexicon_hybrid.py # CLI wrapper
â”‚       â”œâ”€â”€ train_contrastive_encoder.py # CLI wrapper
â”‚       â””â”€â”€ train_classifier_from_encoder.py # CLI wrapper
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ streamlit_app.py            # Interactive demo (TODO)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Features

### âœ… Completed

**Core Infrastructure:**
- Modular data loading and preprocessing
- Comprehensive evaluation metrics (F1, PR-AUC, ROC-AUC)
- Label statistics and analysis utilities

**Models:**
- BiLSTM classifier
- BERT and DistilBERT fine-tuning
- Lexicon-hybrid BERT (combines transformer + lexicon features)
- Contrastive learning encoder

**Research-Grade Utilities:**
- **Calibration**: Temperature scaling, Expected Calibration Error (ECE), Brier score
- **Thresholds**: Per-label threshold optimization
- **Fairness**: Identity bias evaluation with template-based testing
- **Ensembles**: Multiple ensemble strategies (average, max, min, voting, weighted)

**Notebooks:**
- `00_eda_preprocessing.ipynb`: Comprehensive EDA with label distributions, co-occurrence analysis
- `01_baseline_logreg_bilstm.ipynb`: Logistic regression and BiLSTM baselines with comparison

### ðŸš§ TODO

**Remaining Notebooks:**
- Transformer models (BERT, DistilBERT, Lexicon Hybrid)
- Contrastive learning with embedding visualization
- Calibration and threshold tuning analysis
- Fairness and bias evaluation
- Ensemble ablation studies
- Qualitative error analysis

**Demo:**
- Streamlit web interface

## Getting Started

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Data

Place your `train.csv` from Kaggle Jigsaw dataset in `data/jigsaw_train.csv`.

### 3. Run Notebooks

Start with EDA and baselines:
```bash
jupyter notebook notebooks/00_eda_preprocessing.ipynb
```

### 4. Train Models

**From Command Line:**
```bash
# BiLSTM
python -m src.training.train_bilstm

# BERT
python -m src.training.train_transformer --model_type bert

# DistilBERT
python -m src.training.train_transformer --model_type distilbert

# Lexicon Hybrid
python -m src.training.train_lexicon_hybrid

# Contrastive Learning
python -m src.training.train_contrastive_encoder
python -m src.training.train_classifier_from_encoder
```

**From Notebooks:**
```python
from src.training.bilstm_utils import train_bilstm_model
model, vocab, metrics = train_bilstm_model(epochs=5)
```

## Key Design Principles

1. **Modular**: Core logic in `src/`, experiments in notebooks
2. **Reusable**: Training functions can be called from scripts or notebooks
3. **Research-Grade**: Calibration, fairness, ensembles built-in
4. **Zero Duplication**: Utilities shared across all experiments
5. **Professional**: Clean structure suitable for graduate-level projects

## Labels

The Jigsaw dataset includes 6 binary labels:
- `toxic`: General toxicity
- `severe_toxic`: Severe toxicity
- `obscene`: Obscene language
- `threat`: Threats
- `insult`: Insults
- `identity_hate`: Identity-based hate

## Citation

Based on the Jigsaw Toxic Comment Classification Challenge dataset from Kaggle.

## License

For educational purposes.
