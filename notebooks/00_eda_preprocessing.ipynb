{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 0: EDA and Data Preprocessing\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis of the Jigsaw Toxic Comment Classification dataset.\n",
        "\n",
        "## Contents\n",
        "1. Load and inspect data\n",
        "2. Label distribution analysis\n",
        "3. Text length and preprocessing\n",
        "4. Label co-occurrence patterns\n",
        "5. Sample toxic vs non-toxic comments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.config import DATA_DIR, LABELS\n",
        "from src.data_utils import load_raw_jigsaw, get_label_stats, basic_text_clean\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_raw_jigsaw(DATA_DIR / \"jigsaw_train.csv\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Label Distribution Analysis\n",
        "\n",
        "Understanding class imbalance is critical for toxic comment classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_stats = get_label_stats(df)\n",
        "print(\"Label Statistics:\")\n",
        "print(label_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize label distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar plot of counts\n",
        "ax1.bar(label_stats[\"label\"], label_stats[\"count\"], color='steelblue')\n",
        "ax1.set_xlabel(\"Label\")\n",
        "ax1.set_ylabel(\"Positive Count\")\n",
        "ax1.set_title(\"Label Distribution (Absolute Counts)\")\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Bar plot of ratios\n",
        "ax2.bar(label_stats[\"label\"], label_stats[\"ratio\"], color='coral')\n",
        "ax2.set_xlabel(\"Label\")\n",
        "ax2.set_ylabel(\"Positive Ratio\")\n",
        "ax2.set_title(\"Label Distribution (Ratios)\")\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Key observations\n",
        "print(\"\\nKey Observations:\")\n",
        "print(f\"- Most imbalanced label: {label_stats.loc[label_stats['ratio'].idxmin(), 'label']} ({label_stats['ratio'].min():.4f})\")\n",
        "print(f\"- Most common label: {label_stats.loc[label_stats['ratio'].idxmax(), 'label']} ({label_stats['ratio'].max():.4f})\")\n",
        "print(f\"- Overall toxicity rate: {df[LABELS].any(axis=1).mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Length Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"clean_text\"] = df[\"comment_text\"].astype(str).apply(basic_text_clean)\n",
        "df[\"length\"] = df[\"clean_text\"].str.split().apply(len)\n",
        "\n",
        "print(\"Text Length Statistics:\")\n",
        "print(df[\"length\"].describe())\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df[\"length\"], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel(\"Number of Tokens\")\n",
        "axes[0].set_ylabel(\"Frequency\")\n",
        "axes[0].set_title(\"Comment Length Distribution\")\n",
        "axes[0].axvline(df[\"length\"].median(), color='red', linestyle='--', label=f'Median: {df[\"length\"].median():.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot comparing toxic vs non-toxic\n",
        "df[\"any_toxic\"] = df[LABELS].any(axis=1)\n",
        "axes[1].boxplot([df[df[\"any_toxic\"]==False][\"length\"], df[df[\"any_toxic\"]==True][\"length\"]], \n",
        "                 labels=[\"Non-toxic\", \"Toxic\"])\n",
        "axes[1].set_ylabel(\"Number of Tokens\")\n",
        "axes[1].set_title(\"Length: Toxic vs Non-toxic Comments\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Label Co-occurrence Matrix\n",
        "\n",
        "Multi-label datasets often have correlated labels. Understanding these patterns helps model design.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute correlation matrix\n",
        "label_corr = df[LABELS].corr()\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(label_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title(\"Label Co-occurrence Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Count multi-label examples\n",
        "num_labels_per_example = df[LABELS].sum(axis=1)\n",
        "print(\"\\nNumber of labels per example:\")\n",
        "print(num_labels_per_example.value_counts().sort_index())\n",
        "print(f\"\\nExamples with multiple labels: {(num_labels_per_example > 1).sum()} ({(num_labels_per_example > 1).mean():.2%})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sample Comments\n",
        "\n",
        "Let's examine some examples for each label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label in LABELS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Examples for label: {label.upper()}\")\n",
        "    print('='*60)\n",
        "    subset = df[df[label] == 1].head(3)\n",
        "    for idx, row in subset.iterrows():\n",
        "        print(f\"\\n{row['comment_text'][:200]}...\")\n",
        "        print(f\"Labels: {[l for l in LABELS if row[l] == 1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Key Findings:**\n",
        "1. **Class Imbalance**: Rare labels like `threat` and `identity_hate` present significant challenges\n",
        "2. **Text Length**: Toxic comments tend to be slightly shorter than non-toxic ones\n",
        "3. **Multi-label Nature**: Strong correlations exist between certain labels (e.g., `toxic` and `obscene`)\n",
        "4. **Data Quality**: Comments vary significantly in length and style\n",
        "\n",
        "**Implications for Modeling:**\n",
        "- Need techniques to handle class imbalance (focal loss, resampling, class weights)\n",
        "- Rare labels may benefit from specialized approaches (lexicon features, transfer learning)\n",
        "- Multi-label modeling should capture label dependencies\n",
        "- Consider maximum sequence length based on length distribution\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
